{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ffa0161",
   "metadata": {},
   "source": [
    "# 1. Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c099b9b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "It took 0.342 seconds for the training\n",
      "Best max_depth: 4\n",
      "Best Cross-Validation Score: 0.842\n",
      "Decision Tree Classifier Accuracy: 0.839\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.95      0.90     11360\n",
      "           1       0.75      0.51      0.61      3700\n",
      "\n",
      "    accuracy                           0.84     15060\n",
      "   macro avg       0.81      0.73      0.75     15060\n",
      "weighted avg       0.83      0.84      0.83     15060\n",
      "\n",
      "\n",
      "Confusion Matrix\n",
      "[[10746   614]\n",
      " [ 1813  1887]]\n",
      "\n",
      "Feature Importances:\n",
      "relationship: 0.491\n",
      "capital-gain: 0.248\n",
      "education-num: 0.244\n",
      "capital-loss: 0.014\n",
      "age: 0.001\n",
      "fnlwgt: 0.001\n",
      "workclass: 0.0\n",
      "education: 0.0\n",
      "marital-status: 0.0\n",
      "occupation: 0.0\n",
      "race: 0.0\n",
      "sex: 0.0\n",
      "hours-per-week: 0.0\n",
      "native-country: 0.0\n",
      "\n",
      "It took 0.867 seconds for the entire model.\n"
     ]
    }
   ],
   "source": [
    "########################\n",
    "### Import libraries ###\n",
    "########################\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "start_model = time.time()\n",
    "\n",
    "\n",
    "#####################\n",
    "### Load the data ###\n",
    "#####################\n",
    "\n",
    "# Set the columns based on \"adult.names\" file\n",
    "columns = [\"age\", \"workclass\", \"fnlwgt\", \"education\", \"education-num\", \"marital-status\", \"occupation\",\n",
    "           \"relationship\", \"race\", \"sex\", \"capital-gain\", \"capital-loss\", \"hours-per-week\", \"native-country\", \"income\"]\n",
    "\n",
    "train_data = pd.read_csv('adult.data', names=columns, sep=r',\\s+', na_values=[\"?\"])\n",
    "test_data = pd.read_csv('adult.test', names=columns, sep=r',\\s+', na_values=[\"?\"], skiprows=1)\n",
    "\n",
    "\n",
    "###########################\n",
    "### Preprocess the data ###\n",
    "###########################\n",
    "\n",
    "# Drop NA values\n",
    "train_data = train_data.dropna()\n",
    "test_data = test_data.dropna()\n",
    "\n",
    "# Remove period in the income column in the test set\n",
    "test_data['income'] = test_data['income'].str.replace('.', '', regex=False)\n",
    "\n",
    "# Make a new dictionary for label_encoders\n",
    "label_encoders = {}\n",
    "\n",
    "# Convert categorical values into numeric ones using LabelEncoder()\n",
    "for column in train_data.select_dtypes(include=['object']).columns:\n",
    "    label_encoders[column] = LabelEncoder()\n",
    "    train_data[column] = label_encoders[column].fit_transform(train_data[column])\n",
    "    test_data[column] = label_encoders[column].transform(test_data[column])\n",
    "    \n",
    "# Set X_train, X_test, y_train and y_test\n",
    "X_train = train_data.drop(\"income\", axis=1)\n",
    "y_train = train_data[\"income\"]\n",
    "\n",
    "X_test = test_data.drop(\"income\", axis=1)\n",
    "y_test = test_data[\"income\"]\n",
    "\n",
    "def decision_tree_classifier(X_train, y_train, X_test, y_test):\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    \n",
    "    ################################\n",
    "    ### Select a model and train ###\n",
    "    ################################\n",
    "    \n",
    "    start_train = time.time()\n",
    "    \n",
    "    # Set up the RandomForestClassifier\n",
    "    clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "    # Define the parameters for the grid\n",
    "    param_grid = {\n",
    "        'max_depth': [i for i in range(5)]\n",
    "    }\n",
    "\n",
    "    # GridSearchCV\n",
    "    grid_search = GridSearchCV(estimator=clf, param_grid=param_grid, scoring='accuracy', verbose=2, n_jobs=-1)\n",
    "\n",
    "    # Fit the model with GridSearchCV\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    end_train = time.time()\n",
    "    print(f\"It took {round(end_train - start_train,3)} seconds for the training\")\n",
    "    \n",
    "    # Get the best parameters and best score from GridSearchCV\n",
    "\n",
    "    best_max_depth = grid_search.best_params_['max_depth']\n",
    "    best_score = grid_search.best_score_\n",
    "\n",
    "    # Train the final DecisionTreeClassifier with the best max_depth\n",
    "    best_clf = DecisionTreeClassifier(max_depth = best_max_depth, random_state=42)\n",
    "    best_clf.fit(X_train, y_train)\n",
    "\n",
    "    # Print the results\n",
    "    print(f\"Best max_depth: {best_max_depth}\")\n",
    "    print(f\"Best Cross-Validation Score: {round(best_score,3)}\")\n",
    "      \n",
    "\n",
    "    ##################\n",
    "    ### Prediction ###\n",
    "    ##################\n",
    "\n",
    "    # Predictt\n",
    "    predictions = best_clf.predict(X_test)\n",
    "\n",
    "\n",
    "    #######################\n",
    "    ### Measure metrics ###\n",
    "    #######################\n",
    "\n",
    "    # Evaluate and print\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    clf_report = classification_report(y_test, predictions)\n",
    "    confusion_matrix = confusion_matrix(y_test, predictions, labels=[0,1])\n",
    "\n",
    "    print(f\"Decision Tree Classifier Accuracy: {round(accuracy,3)}\\n\")\n",
    "    print(f\"Classification Report\\n{clf_report}\\n\")\n",
    "    print(f\"Confusion Matrix\\n{confusion_matrix}\\n\")\n",
    "\n",
    "\n",
    "    ###########################\n",
    "    ### Feature importances ###\n",
    "    ###########################\n",
    "\n",
    "    # Feature importances\n",
    "    importances = best_clf.feature_importances_\n",
    "    feature_importance_list = sorted(zip(X_train.columns, importances), key=lambda x: x[1], reverse=True)\n",
    "    print(\"Feature Importances:\")\n",
    "    for feature, importance in feature_importance_list:\n",
    "        print(f\"{feature}: {round(importance,3)}\")\n",
    "\n",
    "    end_model = time.time()\n",
    "    print(f\"\\nIt took {round(end_model - start_model,3)} seconds for the entire model.\")\n",
    "\n",
    "decision_tree_classifier(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96cb4a35",
   "metadata": {},
   "source": [
    "# 2. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac9c8b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "It took 44.397 seconds for the training\n",
      "Best n_estimators: 350\n",
      "Best max_depth: 4\n",
      "Best Cross-Validation Score: 0.842\n",
      "Random Forest Classifier Accuracy: 0.84\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.96      0.90     11360\n",
      "           1       0.80      0.47      0.59      3700\n",
      "\n",
      "    accuracy                           0.84     15060\n",
      "   macro avg       0.82      0.72      0.75     15060\n",
      "weighted avg       0.84      0.84      0.82     15060\n",
      "\n",
      "\n",
      "Confusion Matrix\n",
      "[[10916   444]\n",
      " [ 1959  1741]]\n",
      "\n",
      "Feature Importances:\n",
      "relationship: 0.262\n",
      "capital-gain: 0.225\n",
      "marital-status: 0.161\n",
      "education-num: 0.15\n",
      "age: 0.065\n",
      "hours-per-week: 0.041\n",
      "capital-loss: 0.033\n",
      "sex: 0.025\n",
      "education: 0.023\n",
      "occupation: 0.011\n",
      "workclass: 0.002\n",
      "race: 0.001\n",
      "fnlwgt: 0.0\n",
      "native-country: 0.0\n",
      "\n",
      "It took 45.012 seconds for the entire model.\n"
     ]
    }
   ],
   "source": [
    "########################\n",
    "### Import libraries ###\n",
    "########################\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "start_model = time.time()\n",
    "\n",
    "#####################\n",
    "### Load the data ###\n",
    "#####################\n",
    "\n",
    "# Set the columns based on \"adult.names\" file\n",
    "columns = [\"age\", \"workclass\", \"fnlwgt\", \"education\", \"education-num\", \"marital-status\", \"occupation\",\n",
    "           \"relationship\", \"race\", \"sex\", \"capital-gain\", \"capital-loss\", \"hours-per-week\", \"native-country\", \"income\"]\n",
    "\n",
    "train_data = pd.read_csv('adult.data', names=columns, sep=r',\\s+', na_values=[\"?\"])\n",
    "test_data = pd.read_csv('adult.test', names=columns, sep=r',\\s+', na_values=[\"?\"], skiprows=1)\n",
    "\n",
    "\n",
    "###########################\n",
    "### Preprocess the data ###\n",
    "###########################\n",
    "\n",
    "# Drop NA values\n",
    "train_data = train_data.dropna()\n",
    "test_data = test_data.dropna()\n",
    "\n",
    "# Remove period in the income column in the test set\n",
    "test_data['income'] = test_data['income'].str.replace('.', '', regex=False)\n",
    "\n",
    "# Make a new dictionary for label_encoders\n",
    "label_encoders = {}\n",
    "\n",
    "# Convert categorical values into numeric ones using LabelEncoder()\n",
    "for column in train_data.select_dtypes(include=['object']).columns:\n",
    "    label_encoders[column] = LabelEncoder()\n",
    "    train_data[column] = label_encoders[column].fit_transform(train_data[column])\n",
    "    test_data[column] = label_encoders[column].transform(test_data[column])\n",
    "    \n",
    "# Set X_train, X_test, y_train and y_test\n",
    "X_train = train_data.drop(\"income\", axis=1)\n",
    "y_train = train_data[\"income\"]\n",
    "\n",
    "X_test = test_data.drop(\"income\", axis=1)\n",
    "y_test = test_data[\"income\"]\n",
    "\n",
    "\n",
    "def random_forest_classifier(X_train, y_train, X_test, y_test):  \n",
    "    warnings.filterwarnings('ignore')\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "  \n",
    "    ################################\n",
    "    ### Select a model and train ###\n",
    "    ################################\n",
    "    \n",
    "    start_train = time.time()\n",
    "    # Set up the RandomForestClassifier\n",
    "    clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "    # Define the parameter grid (list of n_estimators values to try)\n",
    "    param_grid = {\n",
    "        'n_estimators': [i for i in range(0,500,50)],  \n",
    "        'max_depth': [i for i in range(0,5)]\n",
    "    }\n",
    "\n",
    "    # Set up the GridSearchCV\n",
    "    grid_search = GridSearchCV(estimator=clf, param_grid=param_grid, scoring='accuracy', verbose=2, n_jobs=-1)\n",
    "\n",
    "    # Fit the model with GridSearchCV to find the best n_estimators\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Get the best parameters and best score from GridSearchCV\n",
    "    best_n_estimators = grid_search.best_params_['n_estimators']\n",
    "    best_max_depth = grid_search.best_params_['max_depth']\n",
    "    best_score = grid_search.best_score_\n",
    "\n",
    "    # Train the new RandomForestClassifier with the best_n_estimators and the best_max_depth\n",
    "    best_clf = RandomForestClassifier(n_estimators=best_n_estimators, max_depth = best_max_depth, random_state=42)\n",
    "    best_clf.fit(X_train, y_train)\n",
    "    \n",
    "    end_train = time.time()\n",
    "\n",
    "    print(f\"It took {round(end_train - start_train,3)} seconds for the training\")\n",
    "    \n",
    "    \n",
    "    ##################\n",
    "    ### Prediction ###\n",
    "    ##################\n",
    "    \n",
    "    predictions = best_clf.predict(X_test)\n",
    "    \n",
    "    \n",
    "    #######################\n",
    "    ### Measure metrics ###\n",
    "    #######################\n",
    "\n",
    "    # Evaluate and print\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    clf_report = classification_report(y_test, predictions)\n",
    "    confusion_matrix = confusion_matrix(y_test, predictions, labels=[0,1])\n",
    "        \n",
    "    print(f\"Best n_estimators: {best_n_estimators}\")\n",
    "    print(f\"Best max_depth: {best_max_depth}\")\n",
    "    print(f\"Best Cross-Validation Score: {round(best_score,3)}\")\n",
    "    print(f\"Random Forest Classifier Accuracy: {round(accuracy,3)}\\n\")\n",
    "    print(f\"Classification Report\\n{clf_report}\\n\")\n",
    "    print(f\"Confusion Matrix\\n{confusion_matrix}\\n\")\n",
    "\n",
    "\n",
    "    ###########################\n",
    "    ### Feature importances ###\n",
    "    ###########################\n",
    "\n",
    "    # Feature importances\n",
    "    importances = best_clf.feature_importances_\n",
    "    feature_importance_list = sorted(zip(X_train.columns, importances), key=lambda x: x[1], reverse=True)\n",
    "    print(\"Feature Importances:\")\n",
    "    for feature, importance in feature_importance_list:\n",
    "        print(f\"{feature}: {round(importance,3)}\")\n",
    "\n",
    "    end_model = time.time()\n",
    "    print(f\"\\nIt took {round(end_model - start_model,3)} seconds for the entire model.\")\n",
    "\n",
    "\n",
    "random_forest_classifier(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e97f01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
